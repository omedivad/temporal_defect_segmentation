{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temporal_defect_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4Y7n1po0jNV"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIpKvnWDO5T1"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data.dataset import Dataset  # For custom data-sets\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import argparse\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from tensorflow import summary\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import shutil\n",
        "import scipy.io\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1UPFdF_mgFn"
      },
      "source": [
        "# reproducibility settings\n",
        "\n",
        "random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAJugH753nLj"
      },
      "source": [
        "# ThermoDataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "-4J2Sq90h8NP"
      },
      "source": [
        "class Mapper():\n",
        "  \"\"\"\n",
        "  Define a mapper to map N-channel image where each image is a class in a single\n",
        "  image where the pixel values defines the class\n",
        "  \"\"\"\n",
        "  def __init__(self, color_map: dict = {(0,0,0) : 0, (128,0,0):1, (0,128,0):2}):\n",
        "    \"\"\"\n",
        "    Initialize the Mapper class\n",
        "\n",
        "    Args:\n",
        "      color_map (dict): python dict where vedo se la memoria su colab basta per farlo\n",
        "                          - key are N-channel values, where each\n",
        "                            value represent a class\n",
        "                          - values are the 1-channel corresponding value\n",
        "\n",
        "    Examples:\n",
        "\n",
        "      # in this color_map the key (e.g. (0,0,0) are the N-channel class values)\n",
        "      # while the values (e.g. 0) are the new 1-channel class value\n",
        "\n",
        "      color_map = {(0,0,0) : 0, (128,0,0):1, (0,128,0):2}\n",
        "      mapping = Mapper()\n",
        "    \"\"\"\n",
        "\n",
        "    self.color_map = color_map\n",
        "    self.color_map_inv = {v: k for k, v in color_map.items()}\n",
        "\n",
        "  def __call__(self, mask):\n",
        "    \"\"\"\n",
        "    Call the class instance as a function (e.g. mapper() ) to perform the\n",
        "    mapping operation.\n",
        "\n",
        "    Args:\n",
        "      mask (numpy.ndarray()): N-channel target image\n",
        "    \"\"\"\n",
        "    \n",
        "    mask = np.asarray(mask)\n",
        "    new_mask = np.zeros( (mask.shape[0], mask.shape[1], 1) )\n",
        "\n",
        "    for m in self.color_map:\n",
        "      binary_mask = (mask[:,:,0] == m[0]) & (mask[:,:,1] == m[1]) & (mask[:,:,2] == m[2])\n",
        "\n",
        "      new_mask = new_mask + (binary_mask[..., np.newaxis] * self.color_map[m])\n",
        "\n",
        "    # plt.imshow(new_mask[:,:,0])\n",
        "    # plt.show()\n",
        "    img = Image.fromarray(np.uint8(new_mask[:,:,0])) \n",
        "    # plt.imshow(img)\n",
        "    # plt.show()\n",
        "    return img\n",
        "\n",
        "\n",
        "def normalization_param(dataloader):\n",
        "  \"\"\"\n",
        "  Computes mean and std for a given dataloader\n",
        "  \"\"\"\n",
        "\n",
        "  n_pix = 0\n",
        "  val = 0.0\n",
        "  std_num = 0.0\n",
        "\n",
        "  for batch in dataloader:\n",
        "    # Rearrange batch to be the shape of [B, D,  C, W * H]\n",
        "    batch = batch.view(batch.size(0), -1)\n",
        "    # Update total number of images\n",
        "    n_pix += (batch.size(0)*batch.size(1))\n",
        "    # Compute mean and std here\n",
        "    val += batch.sum(1) \n",
        "\n",
        "  mean = val / n_pix\n",
        "\n",
        "  for batch in dataloader:\n",
        "    # Rearrange batch to be the shape of [B, D,  C, W * H]\n",
        "    batch = batch.view( -1)\n",
        "    std_num += torch.pow((batch - mean),2).sum()\n",
        "\n",
        "  std = torch.sqrt(std_num/n_pix)\n",
        "  \n",
        "  return mean.item(), std.item()\n",
        "\n",
        "\n",
        "class ThermoDatasetPfs(Dataset):\n",
        "  def __init__(self, image_paths, target_paths, mean=None, std=None, train=True):\n",
        "\n",
        "    self.image_paths =  glob.glob(image_paths + \"*.mat\")\n",
        "    self.image_paths.sort()\n",
        "\n",
        "    self.target_paths =  target_paths + \"mask_final.tiff\"\n",
        "    self.mask = Image.open(self.target_paths)\n",
        "    \n",
        "    self.mapping = Mapper({(0,0,0) : 0, (128,0,0):1})\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "\n",
        "    self.mask = self.mapping(self.mask)\n",
        "    self.mask = np.asarray(self.mask)\n",
        "    self.mask = torch.from_numpy(self.mask).long()\n",
        "\n",
        "    self.videos = []\n",
        "\n",
        "    for path in self.image_paths:\n",
        "      v = scipy.io.loadmat(path)['A'][np.newaxis, ...]\n",
        "      v = (v - self.mean) / (self.std)\n",
        "      npad = ((0,0), (0, 0), (1, 1), (1, 1))\n",
        "      v = np.pad(v, pad_width=npad, mode='constant', constant_values=0)\n",
        "      self.videos.append(v)\n",
        "\n",
        "    self.T, _, self.H, self.W = self.videos[0].shape\n",
        "    self.H -= 2\n",
        "    self.W -= 2\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    n_vid = index // (self.H*self.W)\n",
        "    new_idx = index % (self.H*self.W)\n",
        "\n",
        "    n_row = (new_idx // self.W)\n",
        "    n_col = (new_idx % self.W)\n",
        "\n",
        "    # (1, 856, 320, 450)\n",
        "\n",
        "    pixels = self.videos[n_vid][:, :, n_row:n_row+3, n_col:n_col+3]\n",
        "    # image = undersampling(image)\n",
        "\n",
        "    mask_px = self.mask[n_row, n_col][np.newaxis, ...]\n",
        "\n",
        "    return pixels, mask_px\n",
        "\n",
        "  def __len__(self):  # return count of sample we have\n",
        "    l = len(self.image_paths)* self.H * self.W\n",
        "    return l\n",
        "\n",
        "  def get_size(self):\n",
        "    return self.H, self.W\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsQxx8P2Ke-w"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKHRbAPfSSDU"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1S5MwPk-UI"
      },
      "source": [
        "## CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ed4biODEWH7"
      },
      "source": [
        "class BlockTemporal(nn.Sequential):\n",
        "\n",
        "  def __init__(self,\n",
        "                kernel,\n",
        "                in_planes,\n",
        "                out_planes,\n",
        "                stride=1,\n",
        "                padding=1):\n",
        "    super(BlockTemporal, self).__init__(\n",
        "          nn.Conv1d(in_planes, out_planes, kernel_size=kernel,\n",
        "                    stride=stride, padding=padding,\n",
        "                    bias=False))\n",
        "\n",
        "  @staticmethod\n",
        "  def get_downsample_stride(stride):\n",
        "      return stride\n",
        "\n",
        "\n",
        "class BasicBlockTemporal(nn.Module):\n",
        "\n",
        "  def __init__(self, inplanes, planes, conv_builder, kernel=3, stride=1, padding=1, downsample=None):\n",
        "\n",
        "    super(BasicBlockTemporal, self).__init__()\n",
        "\n",
        "    self.conv0 = self.conv1 = nn.Sequential(\n",
        "        nn.Conv1d(inplanes, inplanes, kernel_size=kernel,\n",
        "                    stride=1, padding=padding,\n",
        "                    bias=False),\n",
        "        nn.BatchNorm1d(inplanes),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.conv1 = nn.Sequential(\n",
        "        conv_builder(kernel, inplanes, planes, stride, padding),\n",
        "        nn.BatchNorm1d(planes),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.relu = nn.ReLU()\n",
        "    self.downsample = downsample\n",
        "    self.stride = stride\n",
        "\n",
        "  def forward(self, x):\n",
        "    residual = x\n",
        "\n",
        "    out = self.conv0(x)\n",
        "\n",
        "    out = self.conv1(out)\n",
        "    if self.downsample is not None:\n",
        "        residual = self.downsample(x)\n",
        "\n",
        "    out += residual\n",
        "    out = self.relu(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "class StemTemporal4(nn.Sequential):\n",
        "    \"\"\"R(2+1)D stem is different than the default one as it uses separated 3D convolution\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(StemTemporal4, self).__init__(\n",
        "            nn.Conv3d(1, 128, kernel_size=(13, 3, 3),\n",
        "                      stride=(1), padding=(13//2, 0, 0),\n",
        "                      bias=False),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.ReLU(inplace=True))\n",
        "\n",
        "\n",
        "class TimeResNetTemporal(nn.Module):\n",
        "\n",
        "    def __init__(self, block, conv_makers,\n",
        "                 stem, num_classes=2,\n",
        "                 zero_init_residual=False, hdim=128):\n",
        "        \n",
        "        super(TimeResNetTemporal, self).__init__()\n",
        "\n",
        "        self.stem = stem()\n",
        "\n",
        "        self.layer1 = self._make_layer(block, conv_makers[0], 128, 128, stride=2, padding=1)\n",
        "        self.layer2 = self._make_layer(block, conv_makers[1], 128, 128, stride=2, padding=1)\n",
        "        self.layer3 = self._make_layer(block, conv_makers[2], 128, 128, stride=2, padding=1)\n",
        "        self.layer4 = self._make_layer(block, conv_makers[3], 128, 128, stride=2, padding=1)\n",
        "        self.layer5 = self._make_layer(block, conv_makers[4], 128, 256, stride=2, padding=1)\n",
        "\n",
        "\n",
        "        self.last_conv = nn.Conv1d(256, 2, kernel_size=27,\n",
        "                                   stride=1, padding=0,\n",
        "                                   bias=False)\n",
        "        \n",
        "        # init weights\n",
        "        self._initialize_weights()\n",
        "\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.stem(x).squeeze()\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        \n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        x = self.last_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, conv_builder, inplanes, planes, stride, padding, kernel=3):\n",
        "        downsample = None\n",
        "\n",
        "        if stride != 1 or inplanes != planes:\n",
        "            ds_stride = conv_builder.get_downsample_stride(stride)\n",
        "            # print(\"Downsampled!\")\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv1d(inplanes, planes,\n",
        "                          kernel_size=1, stride=ds_stride, bias=False),\n",
        "                nn.BatchNorm1d(planes)\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, conv_builder, kernel, stride, \n",
        "                            padding, downsample))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv3d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out',\n",
        "                                        nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm3d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def resnetTemporal34(pretrained=False, progress=True):\n",
        "\n",
        "    return TimeResNetTemporal(block=BasicBlockTemporal,\n",
        "                      conv_makers=[BlockTemporal] * 5,\n",
        "                      stem=StemTemporal4, num_classes=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDSANMStk6Ah"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N3O47E6k5XG"
      },
      "source": [
        "class Iou():\n",
        "  \"\"\"\n",
        "  This Class allows to compute IOU both for single classes or in a global \n",
        "  fashion)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_classes: int):\n",
        "    \"\"\" \n",
        "    Initialize class values\n",
        "\n",
        "    Args:\n",
        "      n_classes (int): number of semantic segmentation classes\n",
        "    \"\"\"\n",
        "    self.SMOOTH = 1e-10\n",
        "    self.num_ex = 0\n",
        "    self.n_classes = n_classes\n",
        "    self.ious = np.zeros((n_classes), dtype=np.float32)\n",
        "    \n",
        "\n",
        "  def update(self, out, mask):\n",
        "    \"\"\"\n",
        "    Update class values\n",
        "\n",
        "    Args:\n",
        "      out (torch.Tensor): network output\n",
        "      mask (torch.Tensor): network target\n",
        "    \"\"\"\n",
        "\n",
        "    if len(out.shape) == 4 and out.shape[1] != 1:\n",
        "      out = torch.argmax(out, dim=1)\n",
        "    if len(out.shape) == 4 and mask.shape[1] != 1:\n",
        "      mask = torch.argmax(mask, dim=1)\n",
        "    \n",
        "    # print(\"out: \", torch.unique(out))\n",
        "    # print(\"mask: \", torch.unique(mask))\n",
        "\n",
        "    # updating number of samples\n",
        "    self.num_ex += out.shape[0]\n",
        "\n",
        "    # print(\"intersection: \", np.unique(intersection), intersection.shape)\n",
        "    # print(\"union: \", np.unique(union), union.shape)\n",
        "\n",
        "    # intersection and union shape [BATCH, H, W]\n",
        "\n",
        "    out = out.cpu().detach().numpy() \n",
        "    mask = mask.cpu().detach().numpy() \n",
        "\n",
        "    for c in range(self.n_classes):\n",
        "\n",
        "      o_mask = np.where(out==c, 1, 0)\n",
        "      m_mask = np.where(mask==c, 1, 0) \n",
        "\n",
        "      intersection = (o_mask & m_mask)\n",
        "      union = (o_mask | m_mask)\n",
        "      # print(\"c\", c)\n",
        "\n",
        "      # print(\"inter_mask: \", inter_mask.shape)\n",
        "      i = intersection.sum((1, 2)) + self.SMOOTH\n",
        "\n",
        "      # print(\"union_mask: \", union_mask.shape)\n",
        "      u = union.sum((1, 2)) + self.SMOOTH\n",
        "\n",
        "      # sum batches\n",
        "      self.ious[c] += (i / u).sum((0))\n",
        "\n",
        "      # print(\"ious: \", self.ious.shape)\n",
        "      \n",
        "\n",
        "\n",
        "  def get_iou_classes(self):\n",
        "    \"\"\"\n",
        "    Return classes iou\n",
        "    \n",
        "    Returns:\n",
        "      iou for each class\n",
        "    \"\"\"\n",
        "    return self.ious / self.num_ex\n",
        "\n",
        "\n",
        "  def get_iou_global(self):\n",
        "    \"\"\"\n",
        "    Return global iou\n",
        "    \n",
        "    Returns:\n",
        "      iou \n",
        "    \"\"\"\n",
        "    iou = (self.ious).sum((0)) /  (self.num_ex * self.n_classes)\n",
        "    return iou\n",
        "\n",
        "\n",
        "class ClassAccuracy:\n",
        "  \"\"\"\n",
        "  This Class allows to compute IOU both for single classes or in a global \n",
        "  fashion)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_classes: int):\n",
        "    \"\"\" \n",
        "    Initialize class values\n",
        "\n",
        "    Args:\n",
        "      n_classes (int): number of semantic segmentation classes\n",
        "    \"\"\"\n",
        "    self.num_ex = 0\n",
        "    self.n_classes = n_classes\n",
        "    self.t = np.zeros((n_classes), dtype=np.float32)\n",
        "    self.f = np.zeros((n_classes), dtype=np.float32)\n",
        "\n",
        "\n",
        "  def update(self, out, mask):\n",
        "    \"\"\"\n",
        "    Update class values\n",
        "\n",
        "    Args:\n",
        "      out (torch.Tensor): network output\n",
        "      mask (torch.Tensor): network target\n",
        "    \"\"\"\n",
        "    assert( len(out.shape) == 3)\n",
        "    if len(out.shape) == 4 and out.shape[1] != 1:\n",
        "      out = torch.argmax(out, dim=1)\n",
        "    if len(out.shape) == 4 and mask.shape[1] != 1:\n",
        "      mask = torch.argmax(mask, dim=1)\n",
        "    \n",
        "    # print(\"out: \", torch.unique(out))\n",
        "    # print(\"mask: \", torch.unique(mask))\n",
        "\n",
        "    # updating number of samples\n",
        "    self.num_ex += out.shape[0]*out.shape[1]*out.shape[2]\n",
        "\n",
        "    # print(\"intersection: \", np.unique(intersection), intersection.shape)\n",
        "    # print(\"union: \", np.unique(union), union.shape)\n",
        "\n",
        "    # intersection and union shape [BATCH, H, W]\n",
        "\n",
        "    out = out.cpu().detach().numpy() \n",
        "    mask = mask.cpu().detach().numpy() \n",
        "\n",
        "    for c in range(self.n_classes):\n",
        "\n",
        "      o_mask = np.where(out==c, 1, 0)\n",
        "      m_mask = np.where(mask==c, 1, 0) \n",
        "\n",
        "      self.t[c] = (o_mask == m_mask).sum()\n",
        "      self.f[c] = (o_mask != m_mask).sum()\n",
        "\n",
        "    self.tp = np.sum(np.logical_and(out == 1, mask == 1))\n",
        "    self.tn = np.sum(np.logical_and(out == 0, mask == 0))\n",
        "    self.fp = np.sum(np.logical_and(out == 1, mask == 0))\n",
        "    self.fn = np.sum(np.logical_and(out == 0, mask == 1))\n",
        "      \n",
        "\n",
        "  def get_acc_classes(self):\n",
        "    \"\"\"\n",
        "    Return classes iou\n",
        "    \n",
        "    Returns:\n",
        "      iou for each class\n",
        "    \"\"\"\n",
        "    \n",
        "    return self.t / (self.t + self.f)\n",
        "\n",
        "  def get_metrics(self):\n",
        "    return self.tp, self.tn, self.fp, self.fn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktmb4QqqYc-y"
      },
      "source": [
        "class Ioupf():\n",
        "  \"\"\"\n",
        "  This Class allows to compute IOU both for single classes or in a global \n",
        "  fashion)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, n_classes: int):\n",
        "    \"\"\" \n",
        "    Initialize class values\n",
        "\n",
        "    Args:\n",
        "      n_classes (int): number of semantic segmentation classes\n",
        "    \"\"\"\n",
        "    self.SMOOTH = 1e-10\n",
        "    self.num_ex = 0\n",
        "    self.n_classes = n_classes\n",
        "    self.ious = np.zeros((n_classes), dtype=np.float32)\n",
        "    \n",
        "\n",
        "  def update(self, out, mask):\n",
        "    \"\"\"\n",
        "    Update class values\n",
        "\n",
        "    Args:\n",
        "      out (torch.Tensor): network output\n",
        "      mask (torch.Tensor): network target\n",
        "    \"\"\"\n",
        "\n",
        "    if len(out.shape) == 3 and out.shape[1] != 1:\n",
        "      out = torch.argmax(out, dim=1)\n",
        "    if len(out.shape) == 3 and mask.shape[1] != 1:\n",
        "      mask = torch.argmax(mask, dim=1)\n",
        "    \n",
        "    # print(\"out: \", torch.unique(out))\n",
        "    # print(\"mask: \", torch.unique(mask))\n",
        "\n",
        "    # updating number of samples\n",
        "    self.num_ex += out.shape[0]\n",
        "\n",
        "    # print(\"intersection: \", np.unique(intersection), intersection.shape)\n",
        "    # print(\"union: \", np.unique(union), union.shape)\n",
        "\n",
        "    # intersection and union shape [BATCH, H, W]\n",
        "\n",
        "    out = out.cpu().detach().numpy() \n",
        "    mask = mask.cpu().detach().numpy() \n",
        "\n",
        "    for c in range(self.n_classes):\n",
        "\n",
        "      o_mask = np.where(out==c, 1, 0)\n",
        "      m_mask = np.where(mask==c, 1, 0) \n",
        "\n",
        "      intersection = (o_mask & m_mask)\n",
        "      union = (o_mask | m_mask)\n",
        "      # print(\"c\", c)\n",
        "\n",
        "      # print(\"inter_mask: \", inter_mask.shape)\n",
        "      i = intersection.sum((1, 2)) + self.SMOOTH\n",
        "\n",
        "      # print(\"union_mask: \", union_mask.shape)\n",
        "      u = union.sum((1, 2)) + self.SMOOTH\n",
        "\n",
        "      # sum batches\n",
        "      self.ious[c] += (i / u).sum((0))\n",
        "\n",
        "      # print(\"ious: \", self.ious.shape)\n",
        "      \n",
        "\n",
        "\n",
        "  def get_iou_classes(self):\n",
        "    \"\"\"\n",
        "    Return classes iou\n",
        "    \n",
        "    Returns:\n",
        "      iou for each class\n",
        "    \"\"\"\n",
        "    return self.ious / self.num_ex\n",
        "\n",
        "\n",
        "  def get_iou_global(self):\n",
        "    \"\"\"\n",
        "    Return global iou\n",
        "    \n",
        "    Returns:\n",
        "      iou \n",
        "    \"\"\"\n",
        "    iou = (self.ious).sum((0)) /  (self.num_ex * self.n_classes)\n",
        "    return iou\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw8HkKvT3eJq"
      },
      "source": [
        "# Train/Validation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t63xpQHguf25"
      },
      "source": [
        "def train_cnn(dataloader_train, model, criterion, optim, epoch, logger):\n",
        "    model.train()\n",
        "\n",
        "    for it, (image, mask) in enumerate(tqdm(dataloader_train)):\n",
        "\n",
        "      global_it = (epoch) * len(dataloader_train) + it\n",
        "\n",
        "      image = image.cuda()\n",
        "      mask = mask.cuda()\n",
        "\n",
        "      image = image.float()\n",
        "\n",
        "      # (batch, D, H*W) \n",
        "      out = model(image)\n",
        "      # print(\"OUT shape: \", out.shape)\n",
        "      # print(\"mask shape: \", mask.shape)\n",
        "      loss = criterion(out, mask)\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      logger.add_scalar('Loss/train', loss.item(), global_it)\n",
        "\n",
        "\n",
        "def validatepfs_cnn_traintest(dataloader_val, model, criterion, epoch, logger):\n",
        "\n",
        "  model.eval()\n",
        "  iou_meter = Iou(n_classes=2)\n",
        "  acc_meter = ClassAccuracy(n_classes=2)\n",
        "\n",
        "  H, W = dataloader_val.dataset.get_size()\n",
        "\n",
        "  om = []\n",
        "  msk = []\n",
        "  i=1\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for it, (image, mask) in enumerate(tqdm(dataloader_val)):\n",
        "      global_it = (epoch) * len(dataloader_val) + it\n",
        "\n",
        "      # print(image.shape)\n",
        "\n",
        "      videopx = image.cuda().float()\n",
        "      maskpx = mask.cuda()\n",
        "\n",
        "      outpx = model(videopx)\n",
        "\n",
        "      loss = criterion(outpx, maskpx)\n",
        "\n",
        "      ompx = torch.argmax(outpx, dim=1)\n",
        "\n",
        "      om.append(ompx)\n",
        "      msk.append(maskpx)\n",
        "      logger.add_scalar('Loss/test', loss.item(), global_it)\n",
        "      \n",
        "      if ( ( (it+1) * image.shape[0] ) // (H*W) ) == i:\n",
        "        print(\"Image: \", i)\n",
        "\n",
        "        om1 = torch.stack(om).view(H*W, 1).permute(1, 0).reshape(1, H, W)\n",
        "        msk1 = torch.stack(msk).view(H*W, 1).permute(1, 0).reshape(1, H, W)\n",
        "\n",
        "        om_rgb = decode_segmap(om1)\n",
        "        mask_rgb = decode_segmap(msk1)\n",
        "\n",
        "        iou_meter.update(om1, msk1)\n",
        "        acc_meter.update(om1, msk1)\n",
        "\n",
        "        logger.add_image(\"image/out_rgb\", om_rgb[0], global_it)\n",
        "\n",
        "        logger.add_scalar('Iou/global', iou_meter.get_iou_global() , epoch)\n",
        "        logger.add_scalar('Iou/background', iou_meter.get_iou_classes()[0] , epoch)\n",
        "        logger.add_scalar('Iou/inclusion', iou_meter.get_iou_classes()[1] , epoch)\n",
        "        logger.add_scalar('Acc/background', acc_meter.get_acc_classes()[0] , epoch)\n",
        "        logger.add_scalar('Acc/inclusion', acc_meter.get_acc_classes()[1] , epoch)\n",
        "\n",
        "        print(\"IOU global: \", iou_meter.get_iou_global())\n",
        "        print(\"IOU background: \", iou_meter.get_iou_classes()[0])\n",
        "        print(\"IOU inclusion: \", iou_meter.get_iou_classes()[1])\n",
        "        print(\"Acc background: \", acc_meter.get_acc_classes()[0])\n",
        "        print(\"Acc inclusion: \", acc_meter.get_acc_classes()[1])\n",
        "        print(\"TP: {}, TN: {}, FP: {}, FN: {} \".format(acc_meter.get_metrics()[0],acc_meter.get_metrics()[1], acc_meter.get_metrics()[2], acc_meter.get_metrics()[3]))\n",
        "        om = []\n",
        "        msk = []\n",
        "\n",
        "        i = i+1\n",
        "\n",
        "  return (iou_meter.get_iou_global(), acc_meter.get_acc_classes()[0], acc_meter.get_acc_classes()[1])\n",
        "\n",
        "\n",
        "def save_examples(image, mask, out):\n",
        "  path = master_folder + \"examples/\"\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "  for im in zip(image, mask, out):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15,15))\n",
        "\n",
        "    axs[0].set_title(\"Input Image\")\n",
        "    axs[0].imshow(im[0].transpose(1,2,0).squeeze(2))\n",
        "\n",
        "    axs[1].set_title(\"Input Mask\")\n",
        "    axs[1].imshow(im[1].transpose(1,2,0))\n",
        "\n",
        "\n",
        "    axs[2].set_title(\"Output Mask\")\n",
        "    axs[2].imshow(im[2].transpose(1,2,0))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def decode_segmap(image, nc=2):\n",
        "  \n",
        "  label_colors = np.array([(0, 0, 0),   # 0 = background\n",
        "                          (128, 0, 0),  # 1 = inclusion\n",
        "                          (0, 128, 0),  # 2 = deformation\n",
        "                          ])\n",
        "\n",
        "  r = torch.zeros_like(image, dtype=torch.uint8)\n",
        "  g = torch.zeros_like(image, dtype=torch.uint8)\n",
        "  b = torch.zeros_like(image, dtype=torch.uint8)\n",
        "\n",
        "  for l in range(0, nc):\n",
        "    idx = image == l\n",
        "    r[idx] = label_colors[l, 0]\n",
        "    g[idx] = label_colors[l, 1]\n",
        "    b[idx] = label_colors[l, 2]\n",
        "    \n",
        "  rgb = torch.stack([r, g, b], axis=1)\n",
        "  return rgb\n",
        "\n",
        "def save_checkpoint(state, is_best, check_folder, project_name):\n",
        "  torch.save(state, check_folder+project_name+\".pth\")\n",
        "  if is_best:\n",
        "    shutil.copyfile(check_folder+project_name+\".pth\", check_folder+project_name+\"_model_best.pth\")\n",
        "\n",
        "\n",
        "def load_checkpoint(filename):\n",
        "  return torch.load(filename, map_location=torch.device(\"cpu\"))\n",
        "\n",
        "\n",
        "# install logger\n",
        "# !pip install -q tf-nightly-2.0-preview\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjb1QR7T4p0q"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "2ASiT1vZj7nt"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOf2rhY4iTG"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtpY7meoWO54",
        "cellView": "form"
      },
      "source": [
        "#@title Compute std and mean\n",
        "compute = True #@param {type:\"boolean\"}\n",
        "all_dataset = \"dataset_folder\" #@param {type:\"string\"}\n",
        "\n",
        "# dataset_pf_median\n",
        "mean = 46.406394958496094\n",
        "std = 31.089099884033203\n",
        "\n",
        "if compute:\n",
        "  stooge_dataset = ThermoDataset_base(all_dataset)\n",
        "  stooge_loader = torch.utils.data.DataLoader(stooge_dataset, batch_size=1, shuffle=False)\n",
        "  mean, std = normalization_param(stooge_loader)\n",
        "\n",
        "  print(\"mean :\", mean)\n",
        "  print(\"std: \", std)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yeRvEw1fl_0",
        "cellView": "form"
      },
      "source": [
        "#@title Data, Checkpoint and Annotation folders\n",
        "master_folder = \"master_folder\" #@param {type:\"string\"}\n",
        "\n",
        "image_folder = \"image_folder\" #@param {type:\"string\"}\n",
        "annotation_folder = \"annotation_folder\" #@param {type:\"string\"}\n",
        "logger_folder = \"logs_folder\" #@param {type:\"string\"}\n",
        "project_name = \"project_name\" #@param {type:\"string\"}\n",
        "check_folder = \"checkpoint_folder\" #@param {type:\"string\"}\n",
        "test = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# relative to absolute path\n",
        "image_folder = master_folder+image_folder\n",
        "annotation_folder = master_folder+annotation_folder\n",
        "logger_folder = master_folder+logger_folder + \"/\"\n",
        "check_folder = master_folder+check_folder + \"/\"\n",
        "\n",
        "possible_check = glob.glob(check_folder + \"*.pth\")\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "possible_check.append('No check available')\n",
        "\n",
        "print(\"Select yout checkpoint here: \")\n",
        "print()\n",
        "\n",
        "check_file = widgets.Dropdown(\n",
        "    options=possible_check,\n",
        "    value='No check available',\n",
        "    description='Checkpoint Available:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "display(check_file)\n",
        "print()\n",
        "\n",
        "train_image_paths = image_folder + \"train/data/\"\n",
        "test_image_paths =  image_folder + \"test/data/\"\n",
        "\n",
        "train_mask_paths =  annotation_folder + \"train/annotations/\"\n",
        "test_mask_paths =  annotation_folder + \"test/annotations/\"\n",
        "\n",
        "train_dataset = ThermoDatasetPfs(train_image_paths, train_mask_paths, mean=mean, std=std)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1200, shuffle=True)\n",
        "\n",
        "test_dataset = ThermoDatasetPfs(test_image_paths, test_mask_paths, mean=mean, std=std)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1200, shuffle=False)\n",
        "\n",
        "train_len = len(train_dataset)\n",
        "test_len =  len(test_dataset)\n",
        "len_data =  train_len + test_len\n",
        "print(\"Dataset lenght: \", len_data)\n",
        "print(\"dataset data - train: \", train_len, \"  test: \", test_len)\n",
        "os.makedirs(logger_folder + project_name, exist_ok=True)\n",
        "os.makedirs(check_folder, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "7WmFyDRDzx99"
      },
      "source": [
        "#@title Network parameters\n",
        "\n",
        "\n",
        "learning_rate = 0.000001 #@param {type:\"number\"}\n",
        "start_epoch = 0 #@param {type:\"integer\"}\n",
        "max_epoch =  2046#@param {type:\"integer\"}\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbDlx2gw07AG"
      },
      "source": [
        "# TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k22nIris6b03"
      },
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir \"<logdir>\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKszA5Ff1E0d"
      },
      "source": [
        "# Training/Test execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9QsTQOV48wl"
      },
      "source": [
        "logger = SummaryWriter(logger_folder+project_name,flush_secs=20)\n",
        "torch.cuda.set_device(0)\n",
        "\n",
        "print(\"=> creating model\")\n",
        "model = resnetTemporal34()\n",
        "model = model.cuda()\n",
        "\n",
        "weights=[1.0, 100.0]\n",
        "weights = torch.tensor(weights).cuda()\n",
        "criterion = torch.nn.CrossEntropyLoss(weights).cuda()\n",
        "\n",
        "print(\"=> selecting optimizer\")\n",
        "optim = torch.optim.AdamW(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "\n",
        "\n",
        "best_iou=0\n",
        "\n",
        "if check_file.value != \"No check available\" :\n",
        "  checkpoint = torch.load(check_file.value, map_location='cpu')\n",
        "  model.load_state_dict(checkpoint['model'])\n",
        "  optim.load_state_dict(checkpoint['optimizer'])\n",
        "  start_epoch = checkpoint['epoch'] + 1\n",
        "  best_iou = checkpoint['best_iou']\n",
        "  # lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
        "\n",
        "if test:\n",
        "  print(\"Testing\")\n",
        "  print(\"Epoch: \", start_epoch)\n",
        "  validatepfs_cnn_traintest(test_loader, model, criterion, start_epoch, logger)\n",
        "else :\n",
        "  for e in range(start_epoch, max_epoch):\n",
        "    is_best = False\n",
        "    print(\"Epoch: \", e)\n",
        "    # !nvidia-smi\n",
        "    train_cnn(train_loader, model, criterion, optim, e, logger)\n",
        "    iou, accb, acci = validatepfs_cnn_traintest(test_loader, model, criterion, e, logger)\n",
        "\n",
        "    checkpoint = {\n",
        "              'model': model.state_dict(),\n",
        "              'optimizer': optim.state_dict(),\n",
        "              'best_iou': iou,\n",
        "              'epoch': e,\n",
        "              }\n",
        "    is_best =  iou > best_iou\n",
        "\n",
        "    save_checkpoint(checkpoint, is_best, check_folder=check_folder, project_name=project_name)\n",
        "\n",
        "    if is_best:\n",
        "      best_iou = iou\n",
        "\n",
        "logger.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}